# -*- coding: utf-8 -*-
"""Homework_4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qwphj170aPzxS4rheFPu_CogWgJbgun4
"""

import numpy as np
import pandas as pd
train = pd.read_csv("/content/drive/MyDrive/train.csv")
test = pd.read_csv("/content/drive/MyDrive/test.csv")

"""### NA Detecting and Removing"""

train.isna().sum()

drop_spalten = ["P_CARD_TYPE","REM_CUR","REM_MAX","ANUMBER_02","ANUMBER_03","ANUMBER_04","ANUMBER_05"]
test_3 = test.drop(columns= drop_spalten) # NA's getting removed
train_3 = train.drop(columns= drop_spalten)

"""### NEW FEATURES

"""

# 1. ORDER VALUE PER ITEM
train_3['order_value_per_item'] = np.where(train_3['DEL_AMOUNT_TOTAL'] != 0,
                                            train_3['DEL_VALUE_TOTAL'] / train_3['DEL_AMOUNT_TOTAL'],
                                            0)
test_3['order_value_per_item'] = np.where(test_3['DEL_AMOUNT_TOTAL'] != 0,
                                            test_3['DEL_VALUE_TOTAL'] / test_3['DEL_AMOUNT_TOTAL'],
                                            0)

# I generated a Feature Order Value per Item, because if the customer wants to order a Item with a higher Value increase the chance of order it.

# 2. Contact of the Customer
train_3['contact'] = train.apply(lambda row: 1 if row['O_EMAIL'] or row['O_TELEPHONE'] else 0, axis=1)
test_3['contact'] = test.apply(lambda row: 1 if row['O_EMAIL'] or row['O_TELEPHONE'] else 0, axis=1)

# I created a feature contact, because if a Customer give his contact information, then there is a higher chance that he order.

#3 Contact in the last 3 days
train_3['contact_within_3_days'] = train.apply(lambda row: 1 if row['CHK_LADR'] or row['CHK_RADR'] or row['CHK_KTO'] or row['CHK_CARD'] or row['CHK_COOKIE'] or row['CHK_IP'] else 0, axis=1)
test_3['contact_within_3_days'] = test.apply(lambda row: 1 if row['CHK_LADR'] or row['CHK_RADR'] or row['CHK_KTO'] or row['CHK_CARD'] or row['CHK_COOKIE'] or row['CHK_IP'] else 0, axis=1)

#If there was a contact in the last 3 days the probability of an order increase

#4 Any Fail in the Order
train_3['Any_Fail'] = train.apply(lambda row: 1 if row['FAIL_LPLZ'] or row['FAIL_LORT'] or row['FAIL_LPLZORTMATCH'] or row['FAIL_RPLZ'] or row['FAIL_RORT'] or row['FAIL_RPLZORTMATCH'] else 0, axis=1)
test_3['Any_Fail'] = test.apply(lambda row: 1 if row['FAIL_LPLZ'] or row['FAIL_LORT'] or row['FAIL_LPLZORTMATCH'] or row['FAIL_RPLZ'] or row['FAIL_RORT'] or row['FAIL_RPLZORTMATCH'] else 0, axis=1)

#If there was any Fail with the Customer, the probability that the customer orders decrease

"""### Encoding"""

for columns in train_3.columns:
  if train_3[columns].dtype == "bool" :
    train_3[columns] = train_3[columns].astype("int")

train_3["DEL_DAY"] = train_3["DEL_DAY"].map({"Mo":1,"Di":2,"Mi":3,"Do":4,"Fr":5,"Sa":6,"So":7})
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
train_3["P_METHOD"]=label_encoder.fit_transform(train_3['P_METHOD'])


for columns in test_3.columns:
  if test_3[columns].dtype == "bool" :
    test_3[columns] = test_3[columns].astype("int")

test_3["DEL_DAY"] = test_3["DEL_DAY"].map({"Mo":1,"Di":2,"Mi":3,"Do":4,"Fr":5,"Sa":6,"So":7})
test_3["P_METHOD"]=label_encoder.fit_transform(test_3['P_METHOD'])

"""#### Modell Training"""

from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.model_selection import train_test_split
import xgboost as xgb
remove_columns = ["CHK_KTO","DEL_AMOUNT_TOTAL","CHK_COOKIE","CHK_IP","CHK_RADR","FAIL_LPLZORTMATCH","FAIL_RPLZORTMATCH","CHK_CARD","CHK_LADR","DEL_VALUE_TOTAL","FAIL_RPLZ","Id","FAIL_LPLZ","TARGET_FRAUD","FLAG_NEWSLETTER","FAIL_LORT"]
#The columns that worsen the model have been removed.
X_train_all = train_3.drop(columns=remove_columns)
y_train_all = train_3["TARGET_FRAUD"]

X_train, X_test, y_train, y_test = train_test_split(X_train_all, y_train_all, test_size=0.2, random_state=60, stratify = y_train_all)

# XGM Boosting
#best_auc_xg = 0
#for n in range(240,250):
#  for i in np.arange(0.1, 0.3, 0.05):
#    for l in range(3,10):
#      xg_model = xgb.XGBClassifier(n_estimators = n,learning_rate = i,max_depth = l)
#      xg_model.fit(X_train, y_train)
#      y_pred = xg_model.predict(X_test)

#      y_pred_xg_prob = xg_model.predict_proba(X_test)[:, 1]

#      roc_auc_xg = roc_auc_score(y_test, y_pred_xg_prob)
#     if roc_auc_xg > best_auc_xg:
#        best_auc_xg = roc_auc_xg
#        best_i = i
#        best_n= n
#        best_l = l

xg_model = xgb.XGBClassifier(n_estimators = 150,learning_rate = 0.15,max_depth = 3, seed = 4256813)
xg_model.fit(X_train, y_train)  #model get trained
y_pred = xg_model.predict(X_test)
y_pred_xg_prob = xg_model.predict_proba(X_test)[:, 1]
roc_auc_xg = roc_auc_score(y_test, y_pred_xg_prob)


print(f"ROC AUC Score for XGM Boosting: {roc_auc_xg}")

test_remove_columns = ["CHK_KTO","DEL_AMOUNT_TOTAL","CHK_COOKIE","CHK_IP","CHK_RADR","FAIL_LPLZORTMATCH","FAIL_RPLZORTMATCH","CHK_CARD","CHK_LADR","DEL_VALUE_TOTAL","FAIL_RPLZ","Id","FAIL_LPLZ","FLAG_NEWSLETTER","FAIL_LORT"]
X_pred = test_3.drop(columns=test_remove_columns)
pred_model = xg_model.predict_proba(X_pred)[:, 1]
output_df = pd.DataFrame({
    'Id': test_3['Id'],
    'Target Fraud': pred_model
})
output_df.to_csv('predictions.csv', index=False)